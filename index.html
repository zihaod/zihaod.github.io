<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zihao Deng | University of Pennsylvania</title>
    <link rel="stylesheet" href="assets/css/style.css">
</head>
<body>
    <header>
     
        <nav>
            <ul>
                <li><a href="#home">Home</a></li>
                <li><a href="#about">About Me</a></li>
                <li><a href="#research">Research Interests</a></li>
                <li><a href="#publications">Publications</a></li>
            </ul>
        </nav>
    </header>
    <section id="home">
        <div class="content">
            <div class="text">
                <h2>Zihao Deng</h2>
            </div>
            <div class="text">
                <img src="assets/images/portrait.jpg" alt="" class="portrait">
            </div>
            <div class="text">
                <p>University of Pennsylvania<br>
                zihaoden@seas.upenn.edu<br>
                <a href="https://github.com/zihaod">[Github]</a> <a href="https://scholar.google.com/citations?user=b_UH6wwAAAAJ&hl=en&oi=sra">[Google Scholar]</a></p>
            </div>
        </div>
    </section>
    <section id="about">
        <div class="content">
            <div class="text">
                <h2>About Me</h2>
                <p>I am a graduate student at University of Pennsylvania with a major in Computer and Information Science. Before that, I received my Bachelor of Science in Computer 
                    Science from Carnegie Mellon University, where I was supervised by <a href="https://cbd.cmu.edu/people/xu.html">Prof.Min Xu</a> from <a href="https://xulabs.github.io/">Xu lab</a> 
                    and <a href="https://www.cs.cmu.edu/~morency/">Prof.Louis-Philippe Morency</a> from the <a href="http://multicomp.cs.cmu.edu/">MultiComp Lab</a>, with a research focus on the foundations of
                    multimodal machine learning and their applications.</p>
            </div>
        </div>
    </section>
    <section id="research">
        <div class="content">
            <div class="text">
                <h2>Research Interests</h2>
                <p><b>Multimodal ML</b>: Large multimodal AI systems lie in the core of the current machine learning research, as the models must be capable
                    of processing diverse multimodal signals to be adopted and deployed in more domains. I study the fundamental problems in multimodal machine learning, 
                    including data heterogeneity and interactions, modality alignment and fusion, and scalable multimodal foundation models</p>
                <p><b>Self-supervised and Multimodal Representation Learning</b>: representation learning, as a fundamental research problem that closely relates to the 
                    downstream task performances of any ML models, is inherently complex when heterogeneous data sources are present. Incorporating methods from 
                    information theories and statistical analysis, my research focuses on developing representations that are inclusive of semantic meanings of all data and 
                    the information necessary for a broader range of downstream tasks. Relevant Publications: <br>
                    <ul>
                        <li>Factorized Contrastive Learning and Information Decomposition: <a href="https://arxiv.org/abs/2306.05268">[NeurIPS 2023]</a>, <a href="https://arxiv.org/abs/2302.12247">[NeurIPS 2023]</a></li>
                        <li>Multimodal LLM: <a href="https://arxiv.org/abs/2309.08730">[NAACL 2024]</a></li>
                    </ul></p>
                <p><b>Model Explainability, Safety, and Visualization</b>: The black-box nature of most deep leanring models has significantly hindered their applications to a
                    wider range of high-stake domains where model safety and explainability are of top priority. In order to deploy intelligent multimodal systems with
                    data from healthcare, finance, etc., my research concerns about designing faithful and interpretable explanations for black-box multimodal models. This involves 
                    developing custom ways of presenting or visualizing explanations for different modality inputs, algorithms that explain and analyze cross-modal contribution of 
                    features, and faithful and interpretable designs that unveils the underlying decision workflow of the models. Relevant publications: <br>
                    <ul>
                        <li>Explanation for Multimodal Models: <a href="https://arxiv.org/abs/2203.02013">[AIES 2022]</a>
                        <li>Model Visualization: <a href="https://arxiv.org/abs/2207.00056">[ICLR 2023]</a></li>
                    </ul></p>
                <p><b>ML in Medicine and Healthcare</b>: I have great interests in developing reliable healthcare models that can assist the diagnosis of diseases, surgeries, and health monitoring.
                    We are working on very interesting projects like generating rigorous reports for thyroid nodules based on multi-sensory examination data and also edge devices that run times-series models
                    to monitor the activities and actions of animals. Some common considerations include explainability, robustness, and training with scarse data/domain adaptation.<br>
                    <ul>
                        <li>Domain Randomization and Adaptation: <a href="https://arxiv.org/abs/2111.09114">[Bioinformatics 2021]</a>
                    </ul></p>
            </div>
        </div>
    </section>
    <section id="publications">
        <div class="content">
            <div class="text">
                <h2>Publications</h2>
                <p><b>MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response</b><br>
                    Zihao Deng*, Yinghao Ma*, Yudong Liu, Rongchen Guo, Ge Zhang, Wenhu Chen, Wenhao Huang, Emmanouil Benetos<br>
                    <i>NAACL 2024 </i><a href="https://arxiv.org/abs/2309.08730">[arxiv]</a>.</p>
                <p><b>Factorized Contrastive Learning: Going Beyond Multi-view Redundancy</b><br>
                    Paul Pu Liang*, Zihao Deng*, Martin Ma*, James Zou, Louis-Philippe Morency, Ruslan Salakhutdinov<br>
                    <i>NeurIPS 2023 </i><a href="https://arxiv.org/abs/2306.05268">[arxiv]</a>.</p>
                <p><b>Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework</b><br>
                    Paul Pu Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard Chen, Zihao Deng, Nicholas Allen, Randy Auerbach, Faisal Mahmood, Ruslan Salakhutdinov, Louis-Philippe Morency<br>
                    <i>NeurIPS 2023 </i><a href="https://arxiv.org/abs/2302.12247">[arxiv]</a>.</p>
                <p><b>MultiViz: An Analysis Benchmark for Visualizing and Understanding Multimodal Models</b><br>
                    Paul Pu Liang, Yiwei Lyu, Gunjan Chhablani, Nihal Jain, Zihao Deng, Xingbo Wang, Louis-Philippe Morency, Ruslan Salakhutdinov<br>
                    <i>ICLR 2023 </i><a href="https://arxiv.org/abs/2207.00056">[arxiv]</a>.</p>
                <p><b>Dime: Fine-grained interpretations of multimodal models via disentangled local explanations</b><br>
                    Yiwei Lyu, Paul Pu Liang, Zihao Deng, Ruslan Salakhutdinov, Louis-Philippe Morency<br>
                    <i>AIES 2022 </i><a href="https://arxiv.org/abs/2203.02013">[arxiv]</a>.</p>
                <p><b>Cryo-shift: Reducing domain shift in cryo-electron subtomograms with unsupervised domain adaptation and randomization</b><br>
                    Hmrishav Bandyopadhyay, Zihao Deng, Leiting Ding, Sinuo Liu, Mostofa Rafid Uddin, Xiangrui Zeng, Sima Behpour, Min Xu<br>
                    <i>Bioinformatics 2021 </i><a href="https://arxiv.org/abs/2111.09114">[arxiv]</a>.</p>
                <p>(* denotes equal contribution)</p>
            </div>
        </div>
    </section>
    <!-- 
    <footer>
        <p>&copy; 2024 Zihao Deng</p>
    </footer>-->
</body>
</html>
